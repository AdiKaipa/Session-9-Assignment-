{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning Phrase representation using RNN Encoder-Decoder for WikiQA Dataset (Model 1).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5jprj4HyNGDFDE4GBMeTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiKaipa/Session-9-Assignment-/blob/main/Learning_Phrase_representation_using_RNN_Encoder_Decoder_for_WikiQA_Dataset_(Model_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQcpV46DPBGm"
      },
      "source": [
        "#The WikiQA corpus: A set of publicly available pairs of questions and phrases collected and annotated for research on the answer to open-domain questions. In order to reflect the true information needs of general users, they used Bing query logs as a source of questions. Each question is linked to a Wikipedia page that potentially contains the answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GFXXoo5zKfc",
        "outputId": "cb9a3f2f-eb0e-4a6f-f898-2b0f41f7baaf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVMlp2Kd0BVZ"
      },
      "source": [
        "path_train = '/content/drive/MyDrive/END/END 8/WikiQA.tsv'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqA6vjLB0L9X"
      },
      "source": [
        "import pandas as pd\r\n",
        "df_train = pd.read_csv(path_train, sep = '\\t')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgFadiJf1pJQ",
        "outputId": "5b366964-8cc6-4c28-8d0a-2db2cd6a486a"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29208, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hKwrukQ0l2A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "outputId": "b261a12e-2c8c-4540-a75b-81b84486650f"
      },
      "source": [
        "df_train.head(30)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>Question</th>\n",
              "      <th>DocumentID</th>\n",
              "      <th>DocumentTitle</th>\n",
              "      <th>SentenceID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-0</td>\n",
              "      <td>African immigration to the United States refer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-1</td>\n",
              "      <td>The term African in the scope of this article ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-2</td>\n",
              "      <td>From the Immigration and Nationality Act of 19...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-3</td>\n",
              "      <td>African immigrants in the United States come f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-4</td>\n",
              "      <td>They include people from different national, l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-5</td>\n",
              "      <td>As such, African immigrants are to be distingu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-0</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-1</td>\n",
              "      <td>The ice facade is approximately 60 m high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-2</td>\n",
              "      <td>Ice formations in the Titlis glacier cave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-3</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-4</td>\n",
              "      <td>Glacier caves are often called ice caves , but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-0</td>\n",
              "      <td>In physics , circular motion is a movement of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-1</td>\n",
              "      <td>It can be uniform, with constant angular rate ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-2</td>\n",
              "      <td>The rotation around a fixed axis of a three-di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-3</td>\n",
              "      <td>The equations of motion describe the movement ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-4</td>\n",
              "      <td>Examples of circular motion include: an artifi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-5</td>\n",
              "      <td>Since the object's velocity vector is constant...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Q2</td>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>D2</td>\n",
              "      <td>Circular motion</td>\n",
              "      <td>D2-6</td>\n",
              "      <td>Without this acceleration, the object would mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-0</td>\n",
              "      <td>A prison (from Old French prisoun), also known...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-1</td>\n",
              "      <td>Imprisonment or incarceration is a legal penal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-2</td>\n",
              "      <td>Other terms used are penitentiary, correctiona...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-3</td>\n",
              "      <td>In some legal systems some of these terms have...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-4</td>\n",
              "      <td>A criminal suspect who has been charged with o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-5</td>\n",
              "      <td>A criminal defendant may also be held in priso...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-6</td>\n",
              "      <td>If found guilty, a defendant will be convicted...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-7</td>\n",
              "      <td>As well as convicted or suspected criminals, p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-8</td>\n",
              "      <td>Prisons may also be used as a tool of politica...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-9</td>\n",
              "      <td>In times of war or conflict, prisoners of war ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Q3</td>\n",
              "      <td>how large were early jails</td>\n",
              "      <td>D3</td>\n",
              "      <td>Prison</td>\n",
              "      <td>D3-10</td>\n",
              "      <td>A prison system is the organizational arrangem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Q4</td>\n",
              "      <td>how a water pump works</td>\n",
              "      <td>D4</td>\n",
              "      <td>Pump</td>\n",
              "      <td>D4-0</td>\n",
              "      <td>A small, electrically powered pump</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   QuestionID  ... Label\n",
              "0          Q0  ...     0\n",
              "1          Q0  ...     0\n",
              "2          Q0  ...     0\n",
              "3          Q0  ...     0\n",
              "4          Q0  ...     0\n",
              "5          Q0  ...     1\n",
              "6          Q1  ...     0\n",
              "7          Q1  ...     0\n",
              "8          Q1  ...     0\n",
              "9          Q1  ...     1\n",
              "10         Q1  ...     0\n",
              "11         Q2  ...     0\n",
              "12         Q2  ...     0\n",
              "13         Q2  ...     0\n",
              "14         Q2  ...     0\n",
              "15         Q2  ...     0\n",
              "16         Q2  ...     0\n",
              "17         Q2  ...     0\n",
              "18         Q3  ...     0\n",
              "19         Q3  ...     0\n",
              "20         Q3  ...     0\n",
              "21         Q3  ...     0\n",
              "22         Q3  ...     0\n",
              "23         Q3  ...     0\n",
              "24         Q3  ...     0\n",
              "25         Q3  ...     0\n",
              "26         Q3  ...     0\n",
              "27         Q3  ...     0\n",
              "28         Q3  ...     0\n",
              "29         Q4  ...     0\n",
              "\n",
              "[30 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alGi04Rz2xVb"
      },
      "source": [
        "df_train1 = df_train[df_train['Label'] == 1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "cXLUeO9AXi8b",
        "outputId": "01558c8f-8d63-43c6-b385-11d19c889c55"
      },
      "source": [
        "df_train1.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>Question</th>\n",
              "      <th>DocumentID</th>\n",
              "      <th>DocumentTitle</th>\n",
              "      <th>SentenceID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q0</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>D0</td>\n",
              "      <td>African immigration to the United States</td>\n",
              "      <td>D0-5</td>\n",
              "      <td>As such, African immigrants are to be distingu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-3</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Q4</td>\n",
              "      <td>how a water pump works</td>\n",
              "      <td>D4</td>\n",
              "      <td>Pump</td>\n",
              "      <td>D4-4</td>\n",
              "      <td>Pumps operate by some mechanism (typically rec...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Q11</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>D11</td>\n",
              "      <td>BMC Software</td>\n",
              "      <td>D11-3</td>\n",
              "      <td>Employing over 6,000, BMC is often credited wi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Q11</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>D11</td>\n",
              "      <td>BMC Software</td>\n",
              "      <td>D11-4</td>\n",
              "      <td>For 2011, the company recorded an annual reven...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   QuestionID  ... Label\n",
              "5          Q0  ...     1\n",
              "9          Q1  ...     1\n",
              "33         Q4  ...     1\n",
              "80        Q11  ...     1\n",
              "81        Q11  ...     1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQvRAiimj8WH",
        "outputId": "063b8c80-829d-4056-a541-5d15d388c55e"
      },
      "source": [
        "df_data = df_train1[['Question', 'Sentence']]\r\n",
        "df_data.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1469, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "s1MFQnj5ySKW",
        "outputId": "efdb03c6-615f-411c-debe-68dc6b251114"
      },
      "source": [
        "\r\n",
        "df_data.reset_index(inplace=True)\r\n",
        "df_data.head()\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Question</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>HOW AFRICAN AMERICANS WERE IMMIGRATED TO THE US</td>\n",
              "      <td>As such, African immigrants are to be distingu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>how a water pump works</td>\n",
              "      <td>Pumps operate by some mechanism (typically rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>Employing over 6,000, BMC is often credited wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>81</td>\n",
              "      <td>how big is bmc software in houston, tx</td>\n",
              "      <td>For 2011, the company recorded an annual reven...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                           Sentence\n",
              "0      5  ...  As such, African immigrants are to be distingu...\n",
              "1      9  ...  A glacier cave is a cave formed within the ice...\n",
              "2     33  ...  Pumps operate by some mechanism (typically rec...\n",
              "3     80  ...  Employing over 6,000, BMC is often credited wi...\n",
              "4     81  ...  For 2011, the company recorded an annual reven...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmDcD4f3fyE"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchtext import data\r\n",
        "\r\n",
        "\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzn4ltY53iwz"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOz8zf4A4AG1"
      },
      "source": [
        "SRC = Field(tokenize = 'spacy', \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True)\r\n",
        "TRG = Field(tokenize = 'spacy', \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rYg_Rjt4MFU"
      },
      "source": [
        "fields = [('Question', SRC),('Sentence',TRG)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0FBnmNe5J1B"
      },
      "source": [
        "example = [data.Example.fromlist([df_data.Question[i],df_data.Sentence[i]], fields) for i in range(df_data.shape[0])] "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL2aDgI-5zwS"
      },
      "source": [
        "QADataset = data.Dataset(example, fields)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeH4EjG2y35j",
        "outputId": "e6c630eb-3b41-42a5-bd2f-44e4702e0a70"
      },
      "source": [
        "vars(QADataset.examples[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Question': ['how',\n",
              "  'african',\n",
              "  'americans',\n",
              "  'were',\n",
              "  'immigrated',\n",
              "  'to',\n",
              "  'the',\n",
              "  'us'],\n",
              " 'Sentence': ['as',\n",
              "  'such',\n",
              "  ',',\n",
              "  'african',\n",
              "  'immigrants',\n",
              "  'are',\n",
              "  'to',\n",
              "  'be',\n",
              "  'distinguished',\n",
              "  'from',\n",
              "  'african',\n",
              "  'american',\n",
              "  'people',\n",
              "  ',',\n",
              "  'the',\n",
              "  'latter',\n",
              "  'of',\n",
              "  'whom',\n",
              "  'are',\n",
              "  'descendants',\n",
              "  'of',\n",
              "  'mostly',\n",
              "  'west',\n",
              "  'and',\n",
              "  'central',\n",
              "  'africans',\n",
              "  'who',\n",
              "  'were',\n",
              "  'involuntarily',\n",
              "  'brought',\n",
              "  'to',\n",
              "  'the',\n",
              "  'united',\n",
              "  'states',\n",
              "  'by',\n",
              "  'means',\n",
              "  'of',\n",
              "  'the',\n",
              "  'historic',\n",
              "  'atlantic',\n",
              "  'slave',\n",
              "  'trade',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqFCFW9D5avv"
      },
      "source": [
        "(train, valid) = QADataset.split(split_ratio=[0.90, 0.10], random_state=random.seed(SEED))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOCKTiGfzS6Z",
        "outputId": "0e193466-aaf8-4019-f27b-b158da03918d"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1322, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTVfMYMlzaXC"
      },
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\r\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wq11hNGztcJ",
        "outputId": "735d42db-3862-4ae3-b59e-bf02438aebae"
      },
      "source": [
        "print(\"size of SRC vocab: \", len(SRC.vocab))\r\n",
        "print('size of TRG vocab: ', len(TRG.vocab))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of SRC vocab:  808\n",
            "size of TRG vocab:  3420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkYNzmUK0KfJ"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVWP2yq_0PtL"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "train_iterator, valid_iterator = BucketIterator.splits((train, valid),sort = False, batch_size = BATCH_SIZE, device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2MiySa80Yz0"
      },
      "source": [
        "# Encoder\r\n",
        "class Encoder(nn.Module):\r\n",
        "  def __init__(self, input_dim, emb_dim, hid_dim, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.hid_dim = hid_dim\r\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU(emb_dim, hid_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "  def forward(self, src):\r\n",
        "    embedded = self.dropout(self.embedding(src))\r\n",
        "\r\n",
        "    outputs, hidden = self.rnn(embedded)\r\n",
        "\r\n",
        "       \r\n",
        "    #outputs = [src len, batch size, hid dim * n directions]\r\n",
        "    #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "    return hidden"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tyb2IgB0e7w"
      },
      "source": [
        "# Decoder \r\n",
        "class Decoder(nn.Module):\r\n",
        "  def __init__(self, output_dim, emb_dim, hid_dim, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.hid_dim = hid_dim,\r\n",
        "    self.output_dim = output_dim\r\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\r\n",
        "    self.fc = nn.Linear(emb_dim + hid_dim * 2, output_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "\r\n",
        "  def forward(self, input, hidden, context):\r\n",
        "    #input = [batch size]\r\n",
        "    #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "    #context = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "    #n layers and n directions in the decoder will both always be 1, therefore:\r\n",
        "    #hidden = [1, batch size, hid dim]\r\n",
        "    #context = [1, batch size, hid dim]\r\n",
        "    input = input.unsqueeze(0)\r\n",
        "    embedded = self.dropout(self.embedding(input))\r\n",
        "\r\n",
        "    emb_con = torch.cat((embedded, context), dim = 2)\r\n",
        "    output, hidden = self.rnn(emb_con, hidden)\r\n",
        "        #output = [seq len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\r\n",
        "        #output = [1, batch size, hid dim]\r\n",
        "        #hidden = [1, batch size, hid dim]\r\n",
        "    output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim = 1)\r\n",
        "    prediction = self.fc(output)\r\n",
        "    \r\n",
        "    return prediction, hidden\r\n",
        "    \r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSAqEw9D0kY3"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "  def __init__(self, encoder, decoder, device):\r\n",
        "    super().__init__()\r\n",
        "    self.encoder = encoder\r\n",
        "    self.decoder = decoder\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "    #assert encoder.hid_dim == decoder.hid_dim, \\\r\n",
        "    #  \"Hidden dimensions of encoder and decoder must be equal\"\r\n",
        "  def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "\r\n",
        "    #src = [src len, batch size]\r\n",
        "    #trg = [trg len, batch size]\r\n",
        "    #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "    #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\r\n",
        "\r\n",
        "    batch_size = src.shape[1]\r\n",
        "    trg_len = trg.shape[0]\r\n",
        "    trg_vocab_size = self.decoder.output_dim\r\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "    context = self.encoder(src)\r\n",
        "    hidden = context\r\n",
        "    input = trg[0, :]\r\n",
        "    for t in range(1, trg_len):\r\n",
        "      output, hidden = self.decoder(input, hidden, context)\r\n",
        "      outputs[t] = output\r\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "      top1 = output.argmax(1)\r\n",
        "      input = trg[t] if teacher_force else top1\r\n",
        "    \r\n",
        "    return outputs\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrl4R-pR0pPH"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "ENC_EMB_DIM = 256\r\n",
        "DEC_EMB_DIM = 256\r\n",
        "HID_DIM = 512\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgRgSQ_d0zfG",
        "outputId": "ba7a4265-d5d7-43eb-e11f-36d534e867b9"
      },
      "source": [
        "def init_weights(m):\r\n",
        "  for name, param in m.named_parameters():\r\n",
        "    nn.init.normal_(param.data, mean = 0.0, std = 0.01)\r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(808, 256)\n",
              "    (rnn): GRU(256, 512)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(3420, 256)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc): Linear(in_features=1280, out_features=3420, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a14R2u5003bd",
        "outputId": "23815be3-575b-4103-c918-43a2e43cd44b"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 8,615,260 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCoHmDH-048J"
      },
      "source": [
        "# optimizer\r\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGksXq9v0_Es"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKC80HGh1EoS"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "  model.train()\r\n",
        "  epoch_loss = 0\r\n",
        "  for i, batch in enumerate(iterator):\r\n",
        "    src = batch.Question\r\n",
        "    trg = batch.Sentence\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = model(src, trg)\r\n",
        "    output_dim = output.shape[-1]\r\n",
        "    output = output[1:].view(-1, output_dim)\r\n",
        "    trg = trg[1:].view(-1)\r\n",
        "    loss = criterion(output, trg)\r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "    optimizer.step()\r\n",
        "    epoch_loss += loss.item()\r\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLczrwYz1OZD"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.Question\r\n",
        "            trg = batch.Sentence\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEoHalY1VIe"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcCDmhh_1Yjf",
        "outputId": "0a79dc28-705a-457d-be7c-ee850402a531"
      },
      "source": [
        "N_EPOCHS = 15\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 5s\n",
            "\tTrain Loss: 7.216 | Train PPL: 1361.673\n",
            "\t Val. Loss: 5.218 |  Val. PPL: 184.534\n",
            "Epoch: 02 | Time: 0m 4s\n",
            "\tTrain Loss: 5.854 | Train PPL: 348.763\n",
            "\t Val. Loss: 5.198 |  Val. PPL: 180.944\n",
            "Epoch: 03 | Time: 0m 4s\n",
            "\tTrain Loss: 5.759 | Train PPL: 316.908\n",
            "\t Val. Loss: 5.115 |  Val. PPL: 166.494\n",
            "Epoch: 04 | Time: 0m 4s\n",
            "\tTrain Loss: 5.704 | Train PPL: 300.163\n",
            "\t Val. Loss: 5.107 |  Val. PPL: 165.128\n",
            "Epoch: 05 | Time: 0m 4s\n",
            "\tTrain Loss: 5.643 | Train PPL: 282.281\n",
            "\t Val. Loss: 5.074 |  Val. PPL: 159.852\n",
            "Epoch: 06 | Time: 0m 4s\n",
            "\tTrain Loss: 5.581 | Train PPL: 265.429\n",
            "\t Val. Loss: 5.032 |  Val. PPL: 153.219\n",
            "Epoch: 07 | Time: 0m 4s\n",
            "\tTrain Loss: 5.521 | Train PPL: 249.875\n",
            "\t Val. Loss: 5.045 |  Val. PPL: 155.203\n",
            "Epoch: 08 | Time: 0m 4s\n",
            "\tTrain Loss: 5.456 | Train PPL: 234.065\n",
            "\t Val. Loss: 5.033 |  Val. PPL: 153.433\n",
            "Epoch: 09 | Time: 0m 4s\n",
            "\tTrain Loss: 5.425 | Train PPL: 227.044\n",
            "\t Val. Loss: 5.082 |  Val. PPL: 161.042\n",
            "Epoch: 10 | Time: 0m 4s\n",
            "\tTrain Loss: 5.378 | Train PPL: 216.541\n",
            "\t Val. Loss: 5.058 |  Val. PPL: 157.251\n",
            "Epoch: 11 | Time: 0m 4s\n",
            "\tTrain Loss: 5.374 | Train PPL: 215.775\n",
            "\t Val. Loss: 5.065 |  Val. PPL: 158.329\n",
            "Epoch: 12 | Time: 0m 4s\n",
            "\tTrain Loss: 5.306 | Train PPL: 201.626\n",
            "\t Val. Loss: 5.068 |  Val. PPL: 158.802\n",
            "Epoch: 13 | Time: 0m 4s\n",
            "\tTrain Loss: 5.276 | Train PPL: 195.495\n",
            "\t Val. Loss: 5.051 |  Val. PPL: 156.242\n",
            "Epoch: 14 | Time: 0m 4s\n",
            "\tTrain Loss: 5.254 | Train PPL: 191.372\n",
            "\t Val. Loss: 5.098 |  Val. PPL: 163.724\n",
            "Epoch: 15 | Time: 0m 4s\n",
            "\tTrain Loss: 5.246 | Train PPL: 189.865\n",
            "\t Val. Loss: 5.037 |  Val. PPL: 154.050\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}